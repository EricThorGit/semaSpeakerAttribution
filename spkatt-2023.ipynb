{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gpus for qlora training\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import warnings\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "from datasets import (\n",
    "    load_dataset,\n",
    "    concatenate_datasets,\n",
    "    load_from_disk,\n",
    "    Features,\n",
    "    Sequence,\n",
    "    Value,\n",
    ")\n",
    "from datasets import logging as ds_logging\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import logging as trans_logging\n",
    "\n",
    "from qlora import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_logging.set_verbosity_error()\n",
    "ds_logging.disable_progress_bar()\n",
    "trans_logging.set_verbosity_error()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotations_from_file(path: str, file: str):\n",
    "    features = Features(\n",
    "        {\n",
    "            \"PTC\": Sequence(feature=Value(dtype=\"string\", id=None), length=-1, id=None),\n",
    "            \"Evidence\": Sequence(\n",
    "                feature=Value(dtype=\"string\", id=None), length=-1, id=None\n",
    "            ),\n",
    "            \"Medium\": Sequence(\n",
    "                feature=Value(dtype=\"string\", id=None), length=-1, id=None\n",
    "            ),\n",
    "            \"Topic\": Sequence(\n",
    "                feature=Value(dtype=\"string\", id=None), length=-1, id=None\n",
    "            ),\n",
    "            \"Cue\": Sequence(feature=Value(dtype=\"string\", id=None), length=-1, id=None),\n",
    "            \"Addr\": Sequence(\n",
    "                feature=Value(dtype=\"string\", id=None), length=-1, id=None\n",
    "            ),\n",
    "            \"Message\": Sequence(\n",
    "                feature=Value(dtype=\"string\", id=None), length=-1, id=None\n",
    "            ),\n",
    "            \"Source\": Sequence(\n",
    "                feature=Value(dtype=\"string\", id=None), length=-1, id=None\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "    ds = load_dataset(\n",
    "        \"json\",\n",
    "        data_files=os.path.join(path, file),\n",
    "        field=\"Annotations\",\n",
    "        split=\"train\",\n",
    "        features=features,\n",
    "    )\n",
    "    ds = ds.add_column(\"FileName\", [file] * len(ds))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences_from_file(path: str, file: str):\n",
    "    ds = load_dataset(\n",
    "        \"json\", data_files=os.path.join(path, file), field=\"Sentences\", split=\"train\"\n",
    "    )\n",
    "    ds = ds.add_column(\"FileName\", [file] * len(ds))\n",
    "    ds = ds.add_column(\"Sentence\", [\" \".join(t) for t in ds[\"Tokens\"]])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotations_from_path(path: str):\n",
    "    dataset = None\n",
    "\n",
    "    for file in tqdm(sorted(os.listdir(path))):\n",
    "        if not dataset:\n",
    "            dataset = read_annotations_from_file(path, file)\n",
    "        else:\n",
    "            dataset = concatenate_datasets(\n",
    "                [dataset, read_annotations_from_file(path, file)]\n",
    "            )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences_from_path(path: str):\n",
    "    dataset = None\n",
    "\n",
    "    for file in tqdm(sorted(os.listdir(path))):\n",
    "        if not dataset:\n",
    "            dataset = read_sentences_from_file(path, file)\n",
    "        else:\n",
    "            dataset = concatenate_datasets(\n",
    "                [dataset, read_sentences_from_file(path, file)]\n",
    "            )\n",
    "\n",
    "    dataset = dataset.add_column(\"id\", range(len(dataset)))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences_dataset(ds_name: str):\n",
    "    path_to_dataset = \"./transformed_datasets/\" + ds_name + \"/sentences\"\n",
    "\n",
    "    if os.path.isdir(path_to_dataset):\n",
    "        result = load_from_disk(path_to_dataset)\n",
    "    else:\n",
    "        result = read_sentences_from_path(\n",
    "            \"./SpkAtt-2023/data/\"\n",
    "            + ds_name\n",
    "            + \"/task1\"\n",
    "            + (\"_test/\" if ds_name == \"eval\" else \"/\")\n",
    "        )\n",
    "        os.makedirs(path_to_dataset, exist_ok=True)\n",
    "        result.save_to_disk(path_to_dataset)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotations_dataset(ds_name: str):\n",
    "    path_to_dataset = \"./transformed_datasets/\" + ds_name + \"/annotations\"\n",
    "\n",
    "    if os.path.isdir(path_to_dataset):\n",
    "        return load_from_disk(path_to_dataset)\n",
    "\n",
    "    result = read_annotations_from_path(\n",
    "        \"./SpkAtt-2023/data/\"\n",
    "        + ds_name\n",
    "        + \"/task1\"\n",
    "        + (\"_test/\" if ds_name == \"eval\" else \"/\")\n",
    "    )\n",
    "    os.makedirs(path_to_dataset, exist_ok=True)\n",
    "    result.save_to_disk(path_to_dataset)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_dataset = read_sentences_dataset(\"train\")\n",
    "val_sentences_dataset = read_sentences_dataset(\"dev\")\n",
    "test_sentences_dataset = read_sentences_dataset(\"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations_dataset = read_annotations_dataset(\"train\")\n",
    "val_annotations_dataset = read_annotations_dataset(\"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format datasets for usage in langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_label(train_sentences_dataset, row, annotations):\n",
    "    tokens = []\n",
    "    for anno in annotations:\n",
    "        if int(anno.split(\":\")[0]) == row[\"SentenceId\"]:\n",
    "            tokens.append(row[\"Tokens\"][int(anno.split(\":\")[1])])\n",
    "        else:\n",
    "            temp_row = train_sentences_dataset.filter(\n",
    "                lambda r: r[\"FileName\"] == row[\"FileName\"]\n",
    "                and r[\"SentenceId\"] == int(anno.split(\":\")[0])\n",
    "            )[0]\n",
    "            tokens.append(temp_row[\"Tokens\"][int(anno.split(\":\")[1])])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_complete_dataset(sentences_dataset, annotations_dataset, dataset_name):\n",
    "    path_to_dataset = \"./transformed_datasets/\" + dataset_name + \"/complete\"\n",
    "    if os.path.isdir(path_to_dataset):\n",
    "        return load_from_disk(path_to_dataset)\n",
    "\n",
    "    ptc, ptc_temp, ptc_mapped, ptc_mapped_temp = [], [], [], []\n",
    "    evidence, evidence_temp, evidence_mapped, evidence_mapped_temp = [], [], [], []\n",
    "    medium, medium_temp, medium_mapped, medium_mapped_temp = [], [], [], []\n",
    "    topic, topic_temp, topic_mapped, topic_mapped_temp = [], [], [], []\n",
    "    cue, cue_temp, cue_mapped, cue_mapped_temp = [], [], [], []\n",
    "    addr, addr_temp, addr_mapped, addr_mapped_temp = [], [], [], []\n",
    "    message, message_temp, message_mapped, message_mapped_temp = [], [], [], []\n",
    "    source, source_temp, source_mapped, source_mapped_temp = [], [], [], []\n",
    "    (\n",
    "        sentence_extended,\n",
    "        tokens_extended,\n",
    "        sentence_extended_ids,\n",
    "    ) = (\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "    )\n",
    "\n",
    "    index_in_anno_ds = 0\n",
    "\n",
    "    for i, row in tqdm(enumerate(sentences_dataset)):\n",
    "        context = row[\"Sentence\"]\n",
    "        tokens = row[\"Tokens\"]\n",
    "        ids = [row[\"SentenceId\"]] * len(row[\"Tokens\"])\n",
    "        if (\n",
    "            i + 1 < len(sentences_dataset)\n",
    "            and sentences_dataset[i + 1][\"FileName\"] == row[\"FileName\"]\n",
    "        ):\n",
    "            context = context + \" \" + sentences_dataset[i + 1][\"Sentence\"]\n",
    "            tokens.extend(sentences_dataset[i + 1][\"Tokens\"])\n",
    "            ids.extend(\n",
    "                [sentences_dataset[i + 1][\"SentenceId\"]]\n",
    "                * len(sentences_dataset[i + 1][\"Tokens\"])\n",
    "            )\n",
    "        if (\n",
    "            i + 2 < len(sentences_dataset)\n",
    "            and sentences_dataset[i + 2][\"FileName\"] == row[\"FileName\"]\n",
    "        ):\n",
    "            context = context + \" \" + sentences_dataset[i + 2][\"Sentence\"]\n",
    "            tokens.extend(sentences_dataset[i + 2][\"Tokens\"])\n",
    "            ids.extend(\n",
    "                [sentences_dataset[i + 2][\"SentenceId\"]]\n",
    "                * len(sentences_dataset[i + 2][\"Tokens\"])\n",
    "            )\n",
    "        sentence_extended.append(context)\n",
    "        tokens_extended.append(tokens)\n",
    "        sentence_extended_ids.append(ids)\n",
    "\n",
    "        if annotations_dataset is not None:\n",
    "            id_of_next_sentence_with_annotation = (\n",
    "                int(annotations_dataset[index_in_anno_ds][\"Cue\"][0].split(\":\")[0])\n",
    "                if index_in_anno_ds != len(annotations_dataset)\n",
    "                else -1\n",
    "            )\n",
    "\n",
    "            if row[\"SentenceId\"] != id_of_next_sentence_with_annotation:\n",
    "                ptc.append([])\n",
    "                ptc_mapped.append([])\n",
    "                evidence.append([])\n",
    "                evidence_mapped.append([])\n",
    "                medium.append([])\n",
    "                medium_mapped.append([])\n",
    "                topic.append([])\n",
    "                topic_mapped.append([])\n",
    "                cue.append([])\n",
    "                cue_mapped.append([])\n",
    "                addr.append([])\n",
    "                addr_mapped.append([])\n",
    "                message.append([])\n",
    "                message_mapped.append([])\n",
    "                source.append([])\n",
    "                source_mapped.append([])\n",
    "                continue\n",
    "\n",
    "            while row[\"SentenceId\"] == id_of_next_sentence_with_annotation:\n",
    "                ptc_temp.append(annotations_dataset[index_in_anno_ds][\"PTC\"])\n",
    "                evidence_temp.append(annotations_dataset[index_in_anno_ds][\"Evidence\"])\n",
    "                medium_temp.append(annotations_dataset[index_in_anno_ds][\"Medium\"])\n",
    "                topic_temp.append(annotations_dataset[index_in_anno_ds][\"Topic\"])\n",
    "                cue_temp.append(annotations_dataset[index_in_anno_ds][\"Cue\"])\n",
    "                addr_temp.append(annotations_dataset[index_in_anno_ds][\"Addr\"])\n",
    "                message_temp.append(annotations_dataset[index_in_anno_ds][\"Message\"])\n",
    "                source_temp.append(annotations_dataset[index_in_anno_ds][\"Source\"])\n",
    "\n",
    "                ptc_mapped_temp.append(\n",
    "                    get_text_from_label(sentences_dataset, row, ptc_temp[-1])\n",
    "                )\n",
    "                evidence_mapped_temp.append(\n",
    "                    get_text_from_label(sentences_dataset, row, evidence_temp[-1])\n",
    "                )\n",
    "                medium_mapped_temp.append(\n",
    "                    get_text_from_label(sentences_dataset, row, medium_temp[-1])\n",
    "                )\n",
    "                topic_mapped_temp.append(\n",
    "                    get_text_from_label(sentences_dataset, row, topic_temp[-1])\n",
    "                )\n",
    "                cue_mapped_temp.append(\n",
    "                    get_text_from_label(sentences_dataset, row, cue_temp[-1])\n",
    "                )\n",
    "                addr_mapped_temp.append(\n",
    "                    get_text_from_label(sentences_dataset, row, addr_temp[-1])\n",
    "                )\n",
    "                message_mapped_temp.append(\n",
    "                    get_text_from_label(sentences_dataset, row, message_temp[-1])\n",
    "                )\n",
    "                source_mapped_temp.append(\n",
    "                    get_text_from_label(sentences_dataset, row, source_temp[-1])\n",
    "                )\n",
    "\n",
    "                index_in_anno_ds += 1\n",
    "                if index_in_anno_ds == len(annotations_dataset):\n",
    "                    break\n",
    "                id_of_next_sentence_with_annotation = int(\n",
    "                    annotations_dataset[index_in_anno_ds][\"Cue\"][0].split(\":\")[0]\n",
    "                )\n",
    "\n",
    "            ptc.append(ptc_temp)\n",
    "            ptc_mapped.append(ptc_mapped_temp)\n",
    "            evidence.append(evidence_temp)\n",
    "            evidence_mapped.append(evidence_mapped_temp)\n",
    "            medium.append(medium_temp)\n",
    "            medium_mapped.append(medium_mapped_temp)\n",
    "            topic.append(topic_temp)\n",
    "            topic_mapped.append(topic_mapped_temp)\n",
    "            cue.append(cue_temp)\n",
    "            cue_mapped.append(cue_mapped_temp)\n",
    "            addr.append(addr_temp)\n",
    "            addr_mapped.append(addr_mapped_temp)\n",
    "            message.append(message_temp)\n",
    "            message_mapped.append(message_mapped_temp)\n",
    "            source.append(source_temp)\n",
    "            source_mapped.append(source_mapped_temp)\n",
    "\n",
    "            ptc_temp, ptc_mapped_temp = [], []\n",
    "            evidence_temp, evidence_mapped_temp = [], []\n",
    "            medium_temp, medium_mapped_temp = [], []\n",
    "            topic_temp, topic_mapped_temp = [], []\n",
    "            cue_temp, cue_mapped_temp = [], []\n",
    "            addr_temp, addr_mapped_temp = [], []\n",
    "            message_temp, message_mapped_temp = [], []\n",
    "            source_temp, source_mapped_temp = [], []\n",
    "\n",
    "    res = sentences_dataset.add_column(\"sentence_extended\", sentence_extended)\n",
    "    res = res.add_column(\"tokens_extended\", tokens_extended)\n",
    "    res = res.add_column(\"sentence_extended_ids\", sentence_extended_ids)\n",
    "\n",
    "    if annotations_dataset is not None:\n",
    "        res = res.add_column(\"ptc\", ptc)\n",
    "        res = res.add_column(\"ptc_mapped\", ptc_mapped)\n",
    "        res = res.add_column(\"evidence\", evidence)\n",
    "        res = res.add_column(\"evidence_mapped\", evidence_mapped)\n",
    "        res = res.add_column(\"medium\", medium)\n",
    "        res = res.add_column(\"medium_mapped\", medium_mapped)\n",
    "        res = res.add_column(\"topic\", topic)\n",
    "        res = res.add_column(\"topic_mapped\", topic_mapped)\n",
    "        res = res.add_column(\"cue\", cue)\n",
    "        res = res.add_column(\"cue_mapped\", cue_mapped)\n",
    "        res = res.add_column(\"addr\", addr)\n",
    "        res = res.add_column(\"addr_mapped\", addr_mapped)\n",
    "        res = res.add_column(\"message\", message)\n",
    "        res = res.add_column(\"message_mapped\", message_mapped)\n",
    "        res = res.add_column(\"source\", source)\n",
    "        res = res.add_column(\"source_mapped\", source_mapped)\n",
    "\n",
    "    os.makedirs(path_to_dataset, exist_ok=True)\n",
    "    res.save_to_disk(path_to_dataset)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = build_complete_dataset(\n",
    "    train_sentences_dataset, train_annotations_dataset, \"train\"\n",
    ")\n",
    "val_ds = build_complete_dataset(val_sentences_dataset, val_annotations_dataset, \"dev\")\n",
    "test_ds = build_complete_dataset(test_sentences_dataset, None, \"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = test_sentences_dataset.rename_column(\"Sentence\", \"Satz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Showcase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tokens': ['-',\n",
       "  'Letzter',\n",
       "  'Redner',\n",
       "  'in',\n",
       "  'der',\n",
       "  'Debatte',\n",
       "  ':',\n",
       "  'Bernd',\n",
       "  'Westphal',\n",
       "  'für',\n",
       "  'die',\n",
       "  'SPD-Fraktion',\n",
       "  '.'],\n",
       " 'SentenceId': 52,\n",
       " 'FileName': '19002_Zusatzpunkt_3_CDUCSU_Jung_ID19209800_21.11.2017.json',\n",
       " 'Sentence': '- Letzter Redner in der Debatte : Bernd Westphal für die SPD-Fraktion .',\n",
       " 'id': 52,\n",
       " 'sentence_extended': '- Letzter Redner in der Debatte : Bernd Westphal für die SPD-Fraktion .',\n",
       " 'tokens_extended': ['-',\n",
       "  'Letzter',\n",
       "  'Redner',\n",
       "  'in',\n",
       "  'der',\n",
       "  'Debatte',\n",
       "  ':',\n",
       "  'Bernd',\n",
       "  'Westphal',\n",
       "  'für',\n",
       "  'die',\n",
       "  'SPD-Fraktion',\n",
       "  '.'],\n",
       " 'sentence_extended_ids': [52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52],\n",
       " 'ptc': [[]],\n",
       " 'ptc_mapped': [[]],\n",
       " 'evidence': [[]],\n",
       " 'evidence_mapped': [[]],\n",
       " 'medium': [[]],\n",
       " 'medium_mapped': [[]],\n",
       " 'topic': [[]],\n",
       " 'topic_mapped': [[]],\n",
       " 'cue': [['52:5']],\n",
       " 'cue_mapped': [['Debatte']],\n",
       " 'addr': [[]],\n",
       " 'addr_mapped': [[]],\n",
       " 'message': [[]],\n",
       " 'message_mapped': [[]],\n",
       " 'source': [[]],\n",
       " 'source_mapped': [[]]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tokens': ['Dazu',\n",
       "  'muss',\n",
       "  'man',\n",
       "  'nur',\n",
       "  'mit',\n",
       "  'den',\n",
       "  'Landwirten',\n",
       "  'sprechen',\n",
       "  ',',\n",
       "  'die',\n",
       "  'sagen',\n",
       "  ':',\n",
       "  'Ja',\n",
       "  ',',\n",
       "  'auch',\n",
       "  'früher',\n",
       "  'gab',\n",
       "  'es',\n",
       "  'extreme',\n",
       "  'Ereignisse',\n",
       "  ',',\n",
       "  'auch',\n",
       "  'früher',\n",
       "  'gab',\n",
       "  'es',\n",
       "  'Naturkatastrophen',\n",
       "  ',',\n",
       "  'aber',\n",
       "  'in',\n",
       "  'einem',\n",
       "  'Jahr',\n",
       "  'den',\n",
       "  'Hagel',\n",
       "  ',',\n",
       "  'im',\n",
       "  'anderen',\n",
       "  'Jahr',\n",
       "  'eine',\n",
       "  'Dürre',\n",
       "  'und',\n",
       "  'im',\n",
       "  'dritten',\n",
       "  'Jahr',\n",
       "  ',',\n",
       "  'wie',\n",
       "  'in',\n",
       "  'diesem',\n",
       "  'Jahr',\n",
       "  ',',\n",
       "  'die',\n",
       "  'Frostschäden',\n",
       "  ',',\n",
       "  'unter',\n",
       "  'denen',\n",
       "  'die',\n",
       "  'Obstbauern',\n",
       "  'zu',\n",
       "  'leiden',\n",
       "  'hatten',\n",
       "  ',',\n",
       "  'diese',\n",
       "  'Häufung',\n",
       "  'hatten',\n",
       "  'wir',\n",
       "  'früher',\n",
       "  'so',\n",
       "  'nicht',\n",
       "  ',',\n",
       "  'also',\n",
       "  'tut',\n",
       "  'etwas',\n",
       "  'gegen',\n",
       "  'den',\n",
       "  'Klimawandel',\n",
       "  '.'],\n",
       " 'SentenceId': 15,\n",
       " 'FileName': '19002_Zusatzpunkt_3_CDUCSU_Jung_ID19209800_21.11.2017.json',\n",
       " 'Sentence': 'Dazu muss man nur mit den Landwirten sprechen , die sagen : Ja , auch früher gab es extreme Ereignisse , auch früher gab es Naturkatastrophen , aber in einem Jahr den Hagel , im anderen Jahr eine Dürre und im dritten Jahr , wie in diesem Jahr , die Frostschäden , unter denen die Obstbauern zu leiden hatten , diese Häufung hatten wir früher so nicht , also tut etwas gegen den Klimawandel .',\n",
       " 'id': 15,\n",
       " 'sentence_extended': 'Dazu muss man nur mit den Landwirten sprechen , die sagen : Ja , auch früher gab es extreme Ereignisse , auch früher gab es Naturkatastrophen , aber in einem Jahr den Hagel , im anderen Jahr eine Dürre und im dritten Jahr , wie in diesem Jahr , die Frostschäden , unter denen die Obstbauern zu leiden hatten , diese Häufung hatten wir früher so nicht , also tut etwas gegen den Klimawandel . Es geht um unsere wirtschaftlichen Existenzen . Damit ist die Aufgabe , vor der wir stehen , beschrieben .',\n",
       " 'tokens_extended': ['Dazu',\n",
       "  'muss',\n",
       "  'man',\n",
       "  'nur',\n",
       "  'mit',\n",
       "  'den',\n",
       "  'Landwirten',\n",
       "  'sprechen',\n",
       "  ',',\n",
       "  'die',\n",
       "  'sagen',\n",
       "  ':',\n",
       "  'Ja',\n",
       "  ',',\n",
       "  'auch',\n",
       "  'früher',\n",
       "  'gab',\n",
       "  'es',\n",
       "  'extreme',\n",
       "  'Ereignisse',\n",
       "  ',',\n",
       "  'auch',\n",
       "  'früher',\n",
       "  'gab',\n",
       "  'es',\n",
       "  'Naturkatastrophen',\n",
       "  ',',\n",
       "  'aber',\n",
       "  'in',\n",
       "  'einem',\n",
       "  'Jahr',\n",
       "  'den',\n",
       "  'Hagel',\n",
       "  ',',\n",
       "  'im',\n",
       "  'anderen',\n",
       "  'Jahr',\n",
       "  'eine',\n",
       "  'Dürre',\n",
       "  'und',\n",
       "  'im',\n",
       "  'dritten',\n",
       "  'Jahr',\n",
       "  ',',\n",
       "  'wie',\n",
       "  'in',\n",
       "  'diesem',\n",
       "  'Jahr',\n",
       "  ',',\n",
       "  'die',\n",
       "  'Frostschäden',\n",
       "  ',',\n",
       "  'unter',\n",
       "  'denen',\n",
       "  'die',\n",
       "  'Obstbauern',\n",
       "  'zu',\n",
       "  'leiden',\n",
       "  'hatten',\n",
       "  ',',\n",
       "  'diese',\n",
       "  'Häufung',\n",
       "  'hatten',\n",
       "  'wir',\n",
       "  'früher',\n",
       "  'so',\n",
       "  'nicht',\n",
       "  ',',\n",
       "  'also',\n",
       "  'tut',\n",
       "  'etwas',\n",
       "  'gegen',\n",
       "  'den',\n",
       "  'Klimawandel',\n",
       "  '.',\n",
       "  'Es',\n",
       "  'geht',\n",
       "  'um',\n",
       "  'unsere',\n",
       "  'wirtschaftlichen',\n",
       "  'Existenzen',\n",
       "  '.',\n",
       "  'Damit',\n",
       "  'ist',\n",
       "  'die',\n",
       "  'Aufgabe',\n",
       "  ',',\n",
       "  'vor',\n",
       "  'der',\n",
       "  'wir',\n",
       "  'stehen',\n",
       "  ',',\n",
       "  'beschrieben',\n",
       "  '.'],\n",
       " 'sentence_extended_ids': [15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17],\n",
       " 'ptc': [[], []],\n",
       " 'ptc_mapped': [[], []],\n",
       " 'evidence': [[], []],\n",
       " 'evidence_mapped': [[], []],\n",
       " 'medium': [[], []],\n",
       " 'medium_mapped': [[], []],\n",
       " 'topic': [[], []],\n",
       " 'topic_mapped': [[], []],\n",
       " 'cue': [['15:7'], ['15:10']],\n",
       " 'cue_mapped': [['sprechen'], ['sagen']],\n",
       " 'addr': [['15:4', '15:5', '15:6'], []],\n",
       " 'addr_mapped': [['mit', 'den', 'Landwirten'], []],\n",
       " 'message': [[],\n",
       "  ['15:12',\n",
       "   '15:13',\n",
       "   '15:14',\n",
       "   '15:15',\n",
       "   '15:16',\n",
       "   '15:17',\n",
       "   '15:18',\n",
       "   '15:19',\n",
       "   '15:20',\n",
       "   '15:21',\n",
       "   '15:22',\n",
       "   '15:23',\n",
       "   '15:24',\n",
       "   '15:25',\n",
       "   '15:26',\n",
       "   '15:27',\n",
       "   '15:28',\n",
       "   '15:29',\n",
       "   '15:30',\n",
       "   '15:31',\n",
       "   '15:32',\n",
       "   '15:33',\n",
       "   '15:34',\n",
       "   '15:35',\n",
       "   '15:36',\n",
       "   '15:37',\n",
       "   '15:38',\n",
       "   '15:39',\n",
       "   '15:40',\n",
       "   '15:41',\n",
       "   '15:42',\n",
       "   '15:43',\n",
       "   '15:44',\n",
       "   '15:45',\n",
       "   '15:46',\n",
       "   '15:47',\n",
       "   '15:48',\n",
       "   '15:49',\n",
       "   '15:50',\n",
       "   '15:51',\n",
       "   '15:52',\n",
       "   '15:53',\n",
       "   '15:54',\n",
       "   '15:55',\n",
       "   '15:56',\n",
       "   '15:57',\n",
       "   '15:58',\n",
       "   '15:59',\n",
       "   '15:60',\n",
       "   '15:61',\n",
       "   '15:62',\n",
       "   '15:63',\n",
       "   '15:64',\n",
       "   '15:65',\n",
       "   '15:66',\n",
       "   '15:67',\n",
       "   '15:68',\n",
       "   '15:69',\n",
       "   '15:70',\n",
       "   '15:71',\n",
       "   '15:72',\n",
       "   '15:73',\n",
       "   '15:74',\n",
       "   '16:0',\n",
       "   '16:1',\n",
       "   '16:2',\n",
       "   '16:3',\n",
       "   '16:4',\n",
       "   '16:5']],\n",
       " 'message_mapped': [[],\n",
       "  ['Ja',\n",
       "   ',',\n",
       "   'auch',\n",
       "   'früher',\n",
       "   'gab',\n",
       "   'es',\n",
       "   'extreme',\n",
       "   'Ereignisse',\n",
       "   ',',\n",
       "   'auch',\n",
       "   'früher',\n",
       "   'gab',\n",
       "   'es',\n",
       "   'Naturkatastrophen',\n",
       "   ',',\n",
       "   'aber',\n",
       "   'in',\n",
       "   'einem',\n",
       "   'Jahr',\n",
       "   'den',\n",
       "   'Hagel',\n",
       "   ',',\n",
       "   'im',\n",
       "   'anderen',\n",
       "   'Jahr',\n",
       "   'eine',\n",
       "   'Dürre',\n",
       "   'und',\n",
       "   'im',\n",
       "   'dritten',\n",
       "   'Jahr',\n",
       "   ',',\n",
       "   'wie',\n",
       "   'in',\n",
       "   'diesem',\n",
       "   'Jahr',\n",
       "   ',',\n",
       "   'die',\n",
       "   'Frostschäden',\n",
       "   ',',\n",
       "   'unter',\n",
       "   'denen',\n",
       "   'die',\n",
       "   'Obstbauern',\n",
       "   'zu',\n",
       "   'leiden',\n",
       "   'hatten',\n",
       "   ',',\n",
       "   'diese',\n",
       "   'Häufung',\n",
       "   'hatten',\n",
       "   'wir',\n",
       "   'früher',\n",
       "   'so',\n",
       "   'nicht',\n",
       "   ',',\n",
       "   'also',\n",
       "   'tut',\n",
       "   'etwas',\n",
       "   'gegen',\n",
       "   'den',\n",
       "   'Klimawandel',\n",
       "   '.',\n",
       "   'Es',\n",
       "   'geht',\n",
       "   'um',\n",
       "   'unsere',\n",
       "   'wirtschaftlichen',\n",
       "   'Existenzen']],\n",
       " 'source': [['15:2'], ['15:9']],\n",
       " 'source_mapped': [['man'], ['die']]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build lmsys format json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_cues_to_string(mapped):\n",
    "    if mapped == []:\n",
    "        return \"#UNK#\"\n",
    "    return \", \".join([\"[\" + \", \".join(val) + \"]\" for val in mapped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_roles_to_string(mapped):\n",
    "    if mapped == []:\n",
    "        return \"#UNK#\"\n",
    "    return \", \".join(mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmsys_data_path = \"./lmsys.json\"\n",
    "\n",
    "\n",
    "def build_lmsys_format(train_ds, val_ds):\n",
    "    result = []\n",
    "\n",
    "    index = 0\n",
    "    for row in concatenate_datasets([train_ds, val_ds]):\n",
    "        if len(row[\"cue_mapped\"]) == 0:\n",
    "            element = {\"id\": \"identity_\" + str(index)}\n",
    "            index += 1\n",
    "            conversations = [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": 'A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\\nI want you to extract all cues in the text below.\\nIf you find multiple words for one cue, you output them separated by commas.\\nIf no cue can be found in the given text, you output the string #UNK# as cue.\\nNow extract all cues from the following sentence.\\nUse the prefix \"Cues: \".\\nSentence: '\n",
    "                    + row[\"Sentence\"],\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": \"Cues: \" + map_cues_to_string(row[\"cue_mapped\"]),\n",
    "                },\n",
    "            ]\n",
    "            element[\"conversations\"] = conversations\n",
    "            result.append(element)\n",
    "            continue\n",
    "        for i, cue in enumerate(row[\"cue_mapped\"]):\n",
    "            element = {\"id\": \"identity_\" + str(index)}\n",
    "            index += 1\n",
    "            conversations = [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": 'A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\\nI want you to extract all cues in the text below.\\nIf you find multiple words for one cue, you output them separated by commas.\\nIf no cue can be found in the given text, you output the string #UNK# as cue.\\nNow extract all cues from the following sentence.\\nUse the prefix \"Cues: \".\\nSentence: '\n",
    "                    + row[\"Sentence\"],\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": \"Cues: \" + map_cues_to_string(row[\"cue_mapped\"]),\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": \"Now I give you again the sentence only in addition with the two following sentences, because the roles can be partially contained in the following sentences.\\nText: \"\n",
    "                    + row[\"sentence_extended\"]\n",
    "                    + \"\\n\\nNow find all roles in the sentence associated with the cue '\"\n",
    "                    + \", \".join(cue)\n",
    "                    + \"' you found in the beginning sentence.\",\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": \"cue: \"\n",
    "                    + \", \".join(cue)\n",
    "                    + \"\\nptc: \"\n",
    "                    + map_roles_to_string(row[\"ptc_mapped\"][i])\n",
    "                    + \"\\nevidence: \"\n",
    "                    + map_roles_to_string(row[\"evidence_mapped\"][i])\n",
    "                    + \"\\nmedium: \"\n",
    "                    + map_roles_to_string(row[\"medium_mapped\"][i])\n",
    "                    + \"\\ntopic: \"\n",
    "                    + map_roles_to_string(row[\"topic_mapped\"][i])\n",
    "                    + \"\\naddr: \"\n",
    "                    + map_roles_to_string(row[\"addr_mapped\"][i])\n",
    "                    + \"\\nmessage: \"\n",
    "                    + map_roles_to_string(row[\"message_mapped\"][i])\n",
    "                    + \"\\nsource: \"\n",
    "                    + map_roles_to_string(row[\"source_mapped\"][i]),\n",
    "                },\n",
    "            ]\n",
    "            element[\"conversations\"] = conversations\n",
    "            result.append(element)\n",
    "\n",
    "    with open(lmsys_data_path, \"w\", encoding=\"utf8\") as outfile:\n",
    "        json.dump(result, outfile, indent=3, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_lmsys_format(train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QLoRA Fine-Tuning\n",
    "\n",
    "## Parse data into required format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_cues_file = \"./transformed_datasets/prompts_training/parsed_data_cues.jsonl\"\n",
    "parsed_roles_file = \"./transformed_datasets/prompts_training/parsed_data_roles.jsonl\"\n",
    "os.makedirs(os.path.dirname(parsed_cues_file), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(parsed_roles_file), exist_ok=True)\n",
    "\n",
    "# token to signal the end of the assistant's response\n",
    "separator = \"</s>\"\n",
    "\n",
    "# reload parsed data\n",
    "with open(lmsys_data_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# save parsed prompts separately\n",
    "all_prompts_cues = []\n",
    "all_prompts_roles = []\n",
    "for conversation in data:\n",
    "    # keep track of the complete conversation in order to generate the input of the prompts\n",
    "    complete_prompt = \"\"\n",
    "\n",
    "    for i, turn in enumerate(conversation[\"conversations\"]):\n",
    "        if turn[\"from\"] == \"human\":\n",
    "            complete_prompt += \"User: \"\n",
    "            complete_prompt += turn[\"value\"]\n",
    "        elif turn[\"from\"] == \"gpt\":\n",
    "            complete_prompt += \"Assistant: \"\n",
    "\n",
    "            # idea\n",
    "            # turn 0: user prompt for cues\n",
    "            # turn 1: assistant response with cues\n",
    "            #   --> create sample with the conversation up to this point as input and the cues as output\n",
    "            # turn 2: user prompt for roles for one specific cue\n",
    "            # turn 3: assistant response with roles\n",
    "            #   --> create sample with the conversation up to this point as input and the roles as output\n",
    "            # there should be no further turns because we split all conversations with multiple cues into separate conversations\n",
    "\n",
    "            sample = json.dumps(\n",
    "                {\"input\": complete_prompt, \"output\": turn[\"value\"] + separator}\n",
    "            )\n",
    "\n",
    "            if i == 1 and sample not in all_prompts_cues:\n",
    "                # turn 1: assistant response with cues\n",
    "                all_prompts_cues.append(sample)\n",
    "            elif i == 3 and sample not in all_prompts_cues:\n",
    "                # turn 3: assistant response with roles\n",
    "                all_prompts_roles.append(sample)\n",
    "            elif i != 1 and i != 3:\n",
    "                print(\n",
    "                    \"ERROR: each conversation should maximally contain 4 turns\"\n",
    "                    \" and only turn 1 and 3 should be responses by the assistant\"\n",
    "                )\n",
    "\n",
    "            complete_prompt += turn[\"value\"] + separator\n",
    "        complete_prompt += \"\\n\"\n",
    "\n",
    "# write parsed prompts to files\n",
    "with open(parsed_cues_file, \"w\") as f:\n",
    "    f.write(\"\\n\".join(all_prompts_cues))\n",
    "\n",
    "with open(parsed_roles_file, \"w\") as f:\n",
    "    f.write(\"\\n\".join(all_prompts_roles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 9399\n",
      "\n",
      "First 5 samples:\n",
      "=== in: ===\n",
      "User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Frau Präsidentin !\n",
      "Assistant: \n",
      "\n",
      "=== out: ===\n",
      "Cues: #UNK#</s>\n",
      "\n",
      "\n",
      "=== in: ===\n",
      "User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Liebe Kolleginnen und Kollegen !\n",
      "Assistant: \n",
      "\n",
      "=== out: ===\n",
      "Cues: #UNK#</s>\n",
      "\n",
      "\n",
      "=== in: ===\n",
      "User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Bundeskanzlerin Angela Merkel hat auf der Klimakonferenz in Bonn gesprochen .\n",
      "Assistant: \n",
      "\n",
      "=== out: ===\n",
      "Cues: [gesprochen]</s>\n",
      "\n",
      "\n",
      "=== in: ===\n",
      "User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Sie hat dort den Klimawandel als eine zentrale Herausforderung für die Menschheit bezeichnet .\n",
      "Assistant: \n",
      "\n",
      "=== out: ===\n",
      "Cues: [bezeichnet]</s>\n",
      "\n",
      "\n",
      "=== in: ===\n",
      "User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Sie hat von einer Schicksalsfrage gesprochen .\n",
      "Assistant: \n",
      "\n",
      "=== out: ===\n",
      "Cues: [gesprochen]</s>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the file with the cue prompts was written correctly\n",
    "with open(parsed_cues_file) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(f\"Number of samples: {len(lines)}\\n\")\n",
    "\n",
    "print(\"First 5 samples:\")\n",
    "for l in lines[:5]:\n",
    "    print(\"=== in: ===\\n\" + json.loads(l)[\"input\"] + \"\\n\")\n",
    "    print(\"=== out: ===\\n\" + json.loads(l)[\"output\"] + \"\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 5914\n",
      "\n",
      "First 5 samples:\n",
      "=== in: ===\n",
      "User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Bundeskanzlerin Angela Merkel hat auf der Klimakonferenz in Bonn gesprochen .\n",
      "Assistant: Cues: [gesprochen]</s>\n",
      "User: Now I give you again the sentence only in addition with the two following sentences, because the roles can be partially contained in the following sentences.\n",
      "Text: Bundeskanzlerin Angela Merkel hat auf der Klimakonferenz in Bonn gesprochen . Sie hat dort den Klimawandel als eine zentrale Herausforderung für die Menschheit bezeichnet . Sie hat von einer Schicksalsfrage gesprochen .\n",
      "\n",
      "Now find all roles in the sentence associated with the cue 'gesprochen' you found in the beginning sentence.\n",
      "Assistant: \n",
      "\n",
      "=== out: ===\n",
      "cue: gesprochen\n",
      "ptc: #UNK#\n",
      "evidence: #UNK#\n",
      "medium: #UNK#\n",
      "topic: #UNK#\n",
      "addr: #UNK#\n",
      "message: #UNK#\n",
      "source: Bundeskanzlerin, Angela, Merkel</s>\n",
      "\n",
      "\n",
      "=== in: ===\n",
      "User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Sie hat dort den Klimawandel als eine zentrale Herausforderung für die Menschheit bezeichnet .\n",
      "Assistant: Cues: [bezeichnet]</s>\n",
      "User: Now I give you again the sentence only in addition with the two following sentences, because the roles can be partially contained in the following sentences.\n",
      "Text: Sie hat dort den Klimawandel als eine zentrale Herausforderung für die Menschheit bezeichnet . Sie hat von einer Schicksalsfrage gesprochen . Was sie damit meint , das sieht man , wenn man sich zum Beispiel die Situation der Inselstaaten anschaut .\n",
      "\n",
      "Now find all roles in the sentence associated with the cue 'bezeichnet' you found in the beginning sentence.\n",
      "Assistant: \n",
      "\n",
      "=== out: ===\n",
      "cue: bezeichnet\n",
      "ptc: #UNK#\n",
      "evidence: #UNK#\n",
      "medium: #UNK#\n",
      "topic: den, Klimawandel\n",
      "addr: #UNK#\n",
      "message: als, eine, zentrale, Herausforderung, für, die, Menschheit\n",
      "source: Sie</s>\n",
      "\n",
      "\n",
      "=== in: ===\n",
      "User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Sie hat von einer Schicksalsfrage gesprochen .\n",
      "Assistant: Cues: [gesprochen]</s>\n",
      "User: Now I give you again the sentence only in addition with the two following sentences, because the roles can be partially contained in the following sentences.\n",
      "Text: Sie hat von einer Schicksalsfrage gesprochen . Was sie damit meint , das sieht man , wenn man sich zum Beispiel die Situation der Inselstaaten anschaut . Die Fidschi-Inseln standen in besonderer Weise im Mittelpunkt der Konferenz , weil die Fidschis die Präsidentschaft übernommen hatten .\n",
      "\n",
      "Now find all roles in the sentence associated with the cue 'gesprochen' you found in the beginning sentence.\n",
      "Assistant: \n",
      "\n",
      "=== out: ===\n",
      "cue: gesprochen\n",
      "ptc: #UNK#\n",
      "evidence: #UNK#\n",
      "medium: #UNK#\n",
      "topic: #UNK#\n",
      "addr: #UNK#\n",
      "message: von, einer, Schicksalsfrage\n",
      "source: Sie</s>\n",
      "\n",
      "\n",
      "=== in: ===\n",
      "User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Was sie damit meint , das sieht man , wenn man sich zum Beispiel die Situation der Inselstaaten anschaut .\n",
      "Assistant: Cues: [meint], [sieht]</s>\n",
      "User: Now I give you again the sentence only in addition with the two following sentences, because the roles can be partially contained in the following sentences.\n",
      "Text: Was sie damit meint , das sieht man , wenn man sich zum Beispiel die Situation der Inselstaaten anschaut . Die Fidschi-Inseln standen in besonderer Weise im Mittelpunkt der Konferenz , weil die Fidschis die Präsidentschaft übernommen hatten . Wenn man bedenkt , dass es Inseln gibt , die von Überflutung bedroht sind , dass es dort Menschen gibt , die schon heute ihre Heimat verloren haben , deren Existenz , deren Inseln , deren Heimat durch den Klimawandel bedroht sind , wenn man sich vergegenwärtigt , dass es Umsiedlungen gibt , wenn man also weiß , dass es Menschen gibt , die wegen des Klimawandels flüchten - es gibt Menschen , die zu Klimaflüchtlingen werden - , dann muss man sagen : Wer etwas für die Bekämpfung der Fluchtursachen tun möchte , der muss stark für Klimaschutz sein .\n",
      "\n",
      "Now find all roles in the sentence associated with the cue 'meint' you found in the beginning sentence.\n",
      "Assistant: \n",
      "\n",
      "=== out: ===\n",
      "cue: meint\n",
      "ptc: #UNK#\n",
      "evidence: #UNK#\n",
      "medium: #UNK#\n",
      "topic: #UNK#\n",
      "addr: #UNK#\n",
      "message: Was\n",
      "source: sie</s>\n",
      "\n",
      "\n",
      "=== in: ===\n",
      "User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Was sie damit meint , das sieht man , wenn man sich zum Beispiel die Situation der Inselstaaten anschaut .\n",
      "Assistant: Cues: [meint], [sieht]</s>\n",
      "User: Now I give you again the sentence only in addition with the two following sentences, because the roles can be partially contained in the following sentences.\n",
      "Text: Was sie damit meint , das sieht man , wenn man sich zum Beispiel die Situation der Inselstaaten anschaut . Die Fidschi-Inseln standen in besonderer Weise im Mittelpunkt der Konferenz , weil die Fidschis die Präsidentschaft übernommen hatten . Wenn man bedenkt , dass es Inseln gibt , die von Überflutung bedroht sind , dass es dort Menschen gibt , die schon heute ihre Heimat verloren haben , deren Existenz , deren Inseln , deren Heimat durch den Klimawandel bedroht sind , wenn man sich vergegenwärtigt , dass es Umsiedlungen gibt , wenn man also weiß , dass es Menschen gibt , die wegen des Klimawandels flüchten - es gibt Menschen , die zu Klimaflüchtlingen werden - , dann muss man sagen : Wer etwas für die Bekämpfung der Fluchtursachen tun möchte , der muss stark für Klimaschutz sein .\n",
      "\n",
      "Now find all roles in the sentence associated with the cue 'sieht' you found in the beginning sentence.\n",
      "Assistant: \n",
      "\n",
      "=== out: ===\n",
      "cue: sieht\n",
      "ptc: #UNK#\n",
      "evidence: #UNK#\n",
      "medium: #UNK#\n",
      "topic: #UNK#\n",
      "addr: #UNK#\n",
      "message: das\n",
      "source: man</s>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the file with the role prompts was written correctly\n",
    "with open(parsed_roles_file) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(f\"Number of samples: {len(lines)}\\n\")\n",
    "\n",
    "print(\"First 5 samples:\")\n",
    "for l in lines[:5]:\n",
    "    print(\"=== in: ===\\n\" + json.loads(l)[\"input\"] + \"\\n\")\n",
    "    print(\"=== out: ===\\n\" + json.loads(l)[\"output\"] + \"\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Check optimal source and target lengths\n",
    "\n",
    "This step is only required if you want to use your own data. If you use the original GermEval 2023 task 1 data, you can skip this step and use the source and target lengths that are already defined in the config files in the `configs` folder (parameters `source_max_len` and `target_max_len`).\n",
    "\n",
    "If you want to change the maximum source or target lengths, keep in mind that longer prompts mean longer training times and more memory requirements. While it would be best to set the maximum source/target lengths to the maximum lengths of the inputs/outputs, this is not always feasible due to memory constraints. In this case, we recommend choosing maximum lengths that only truncate few samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4822f6d327784673a2e048579d68210e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489d3b5886b24958b3fa49990b54c1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bc356edcd34f7e99e33b761ecf523b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/700 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tobias\\Nextcloud\\FH Aachen\\10. Semester\\Masterarbeit\\paper-code\\spkatt-2023.ipynb Cell 34\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tobias/Nextcloud/FH%20Aachen/10.%20Semester/Masterarbeit/paper-code/spkatt-2023.ipynb#X45sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m enc_in \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(json\u001b[39m.\u001b[39mloads(l)[\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tobias/Nextcloud/FH%20Aachen/10.%20Semester/Masterarbeit/paper-code/spkatt-2023.ipynb#X45sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m encoded_inputs_roles\u001b[39m.\u001b[39mappend(enc_in)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tobias/Nextcloud/FH%20Aachen/10.%20Semester/Masterarbeit/paper-code/spkatt-2023.ipynb#X45sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m enc_out \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39;49mencode(json\u001b[39m.\u001b[39;49mloads(l)[\u001b[39m\"\u001b[39;49m\u001b[39moutput\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tobias/Nextcloud/FH%20Aachen/10.%20Semester/Masterarbeit/paper-code/spkatt-2023.ipynb#X45sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m encoded_outputs_roles\u001b[39m.\u001b[39mappend(enc_out)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2348\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[0;32m   2311\u001b[0m \u001b[39m@add_end_docstrings\u001b[39m(\n\u001b[0;32m   2312\u001b[0m     ENCODE_KWARGS_DOCSTRING,\n\u001b[0;32m   2313\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2331\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2332\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mint\u001b[39m]:\n\u001b[0;32m   2333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2334\u001b[0m \u001b[39m    Converts a string to a sequence of ids (integer), using the tokenizer and vocabulary.\u001b[39;00m\n\u001b[0;32m   2335\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2346\u001b[0m \u001b[39m            method).\u001b[39;00m\n\u001b[0;32m   2347\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2348\u001b[0m     encoded_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[0;32m   2349\u001b[0m         text,\n\u001b[0;32m   2350\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   2351\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2352\u001b[0m         padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   2353\u001b[0m         truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   2354\u001b[0m         max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m   2355\u001b[0m         stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m   2356\u001b[0m         return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2357\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2358\u001b[0m     )\n\u001b[0;32m   2360\u001b[0m     \u001b[39mreturn\u001b[39;00m encoded_inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2756\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2746\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   2747\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2748\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   2749\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2753\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2754\u001b[0m )\n\u001b[1;32m-> 2756\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_plus(\n\u001b[0;32m   2757\u001b[0m     text\u001b[39m=\u001b[39mtext,\n\u001b[0;32m   2758\u001b[0m     text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   2759\u001b[0m     add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2760\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m   2761\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   2762\u001b[0m     max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[0;32m   2763\u001b[0m     stride\u001b[39m=\u001b[39mstride,\n\u001b[0;32m   2764\u001b[0m     is_split_into_words\u001b[39m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2765\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2766\u001b[0m     return_tensors\u001b[39m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2767\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2768\u001b[0m     return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2769\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2770\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2771\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2772\u001b[0m     return_length\u001b[39m=\u001b[39mreturn_length,\n\u001b[0;32m   2773\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m   2774\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2775\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\tokenization_utils.py:649\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[39mif\u001b[39;00m return_offsets_mapping:\n\u001b[0;32m    641\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    642\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    643\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 649\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(text)\n\u001b[0;32m    650\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(text_pair) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_for_model(\n\u001b[0;32m    653\u001b[0m     first_ids,\n\u001b[0;32m    654\u001b[0m     pair_ids\u001b[39m=\u001b[39msecond_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    668\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m    669\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\tokenization_utils.py:616\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus.<locals>.get_input_ids\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_input_ids\u001b[39m(text):\n\u001b[0;32m    615\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 616\u001b[0m         tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenize(text, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    617\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[0;32m    618\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(text[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\models\\llama\\tokenization_llama.py:174\u001b[0m, in \u001b[0;36mLlamaTokenizer.tokenize\u001b[1;34m(self, text, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlegacy:\n\u001b[0;32m    173\u001b[0m     text \u001b[39m=\u001b[39m SPIECE_UNDERLINE \u001b[39m+\u001b[39m text\u001b[39m.\u001b[39mreplace(SPIECE_UNDERLINE, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mtokenize(text, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\tokenization_utils.py:517\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[1;34m(self, text, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m     text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(pattern, \u001b[39mlambda\u001b[39;00m m: m\u001b[39m.\u001b[39mgroups()[\u001b[39m0\u001b[39m] \u001b[39mor\u001b[39;00m m\u001b[39m.\u001b[39mgroups()[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mlower(), text)\n\u001b[0;32m    516\u001b[0m no_split_token \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munique_no_split_tokens)\n\u001b[1;32m--> 517\u001b[0m tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokens_trie\u001b[39m.\u001b[39;49msplit(text)\n\u001b[0;32m    518\u001b[0m \u001b[39m# [\"This is something\", \"<special_token_1>\", \"  else\"]\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \u001b[39mfor\u001b[39;00m i, token \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tokens):\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\anaconda3\\envs\\thesis\\lib\\site-packages\\transformers\\tokenization_utils.py:135\u001b[0m, in \u001b[0;36mTrie.split\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    133\u001b[0m skip \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[39m# Main loop, Giving this algorithm O(n) complexity\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m \u001b[39mfor\u001b[39;00m current, current_char \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(text):\n\u001b[0;32m    136\u001b[0m     \u001b[39mif\u001b[39;00m skip \u001b[39mand\u001b[39;00m current \u001b[39m<\u001b[39m skip:\n\u001b[0;32m    137\u001b[0m         \u001b[39m# Prevents the lookahead for matching twice\u001b[39;00m\n\u001b[0;32m    138\u001b[0m         \u001b[39m# like extra_id_100 and id_100\u001b[39;00m\n\u001b[0;32m    139\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# encode all prompt inputs with the Llama 1 tokenizer (same as the Llama 2 tokenizer)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"huggyllama/llama-7b\", padding_side=\"right\", use_fast=False, tokenizer_type=\"llama\"\n",
    ")\n",
    "\n",
    "encoded_inputs_cues = []\n",
    "encoded_inputs_roles = []\n",
    "encoded_outputs_cues = []\n",
    "encoded_outputs_roles = []\n",
    "with open(parsed_cues_file) as f:\n",
    "    for l in f.readlines():\n",
    "        enc_in = tokenizer.encode(json.loads(l)[\"input\"])\n",
    "        encoded_inputs_cues.append(enc_in)\n",
    "        enc_out = tokenizer.encode(json.loads(l)[\"output\"])\n",
    "        encoded_outputs_cues.append(enc_out)\n",
    "with open(parsed_roles_file) as f:\n",
    "    for l in f.readlines():\n",
    "        enc_in = tokenizer.encode(json.loads(l)[\"input\"])\n",
    "        encoded_inputs_roles.append(enc_in)\n",
    "        enc_out = tokenizer.encode(json.loads(l)[\"output\"])\n",
    "        encoded_outputs_roles.append(enc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# maximum source lengths taken from the config files\n",
    "max_length_source_cues = 256\n",
    "max_length_source_roles = 640\n",
    "\n",
    "print(\"cues source lengths\")\n",
    "len_enc = [len(e) for e in encoded_inputs_cues]\n",
    "print(f\"max length: {max(len_enc)}\")\n",
    "print(f\"mean length: {np.mean(len_enc)}\")\n",
    "print(\n",
    "    f\"number of samples longer than {max_length_source_cues}: {sum(np.array(len_enc) > max_length_source_cues)}\"\n",
    ")\n",
    "print()\n",
    "\n",
    "print(\"roles source lengths\")\n",
    "len_enc = [len(e) for e in encoded_inputs_roles]\n",
    "print(f\"max length: {max(len_enc)}\")\n",
    "print(f\"mean length: {np.mean(len_enc)}\")\n",
    "print(\n",
    "    f\"number of samples longer than {max_length_source_roles}: {sum(np.array(len_enc) > max_length_source_roles)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# maximum target lengths taken from the config files\n",
    "max_length_target_cues = 64\n",
    "max_length_target_roles = 256\n",
    "\n",
    "print(\"cues target lengths\")\n",
    "len_enc = [len(e) for e in encoded_outputs_cues]\n",
    "print(f\"max length: {max(len_enc)}\")\n",
    "print(f\"mean length: {np.mean(len_enc)}\")\n",
    "print(\n",
    "    f\"number of samples longer than {max_length_target_cues}: {sum(np.array(len_enc) > max_length_target_cues)}\"\n",
    ")\n",
    "print()\n",
    "\n",
    "print(\"roles target lengths\")\n",
    "len_enc = [len(e) for e in encoded_outputs_roles]\n",
    "print(f\"max length: {max(len_enc)}\")\n",
    "print(f\"mean length: {np.mean(len_enc)}\")\n",
    "print(\n",
    "    f\"number of samples longer than {max_length_target_roles}: {sum(np.array(len_enc) > max_length_target_roles)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train models\n",
    "\n",
    "This step can be skipped if you already have trained models.\n",
    "\n",
    "For training, you first have to prepare the Llama 2 models and adapt the configuration. To prepare the Llama 2 models, you will have to make them accessible in HF (Huggingface) format. You can either use the models directly from Huggingface or prepare them yourself by first downloading the model weights from [the official Llama repo](https://github.com/facebookresearch/llama) and then converting these weights using their [conversion manual](https://github.com/facebookresearch/llama-recipes/#model-conversion-to-hugging-face). When using the models from Huggingface, you should add the parameter `use_auth_token` with your Huggingface token to the training configs in the `configs` folder. If you don't want to use the models from Huggingface, once you have prepared the models yourself, update the path to the models in the config files (parameter `model_name_or_path`) in the `configs` folder so the paths point to the folder containing the `pytorch_model-000xx-of-00015.bin` files.\n",
    "\n",
    "Further configuration parameters:\n",
    "\n",
    "- `per_device_train_batch_size` and `gradient_accumulation_steps`: With these two parameters you can control the batch size and the number of accumulation steps when calculating the gradients during training. Larger batch sizes should speed up training, but increase memory requirements considerably. We recommend choosing the parameters so that their product `per_device_train_batch_size * gradient_accumulation_steps` is a multiple of 16.\n",
    "- `save_steps` and `max_steps`: set `max_steps` to control the length of training (`save_steps` determines when checkpoints are created)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose config for cue model\n",
    "cues_training_config = \"./configs/7b_cues.args\"  # 7b model\n",
    "# cues_training_config = \"./configs/70b_cues.args\" # 70b model\n",
    "\n",
    "train(cues_training_config)\n",
    "\n",
    "# free vram after training\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose config for roles model\n",
    "roles_training_config = \"./configs/7b_roles.args\"  # 7b model\n",
    "# roles_training_config = \"./configs/70b_roles.args\" # 70b model\n",
    "\n",
    "train(roles_training_config)\n",
    "\n",
    "# free vram after training\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define config files for training\n",
    "# 7B models\n",
    "cues_training_config = {\n",
    "    \"model_name_or_path\": \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"output_dir\": \"./output/spkatt-7b-cues\",\n",
    "    \"data_seed\": 42,\n",
    "    \"save_steps\": 200,\n",
    "    \"evaluation_strategy\": \"no\",\n",
    "    \"dataloader_num_workers\": 4,\n",
    "    \"lora_modules\": \"all\",\n",
    "    \"bf16\": True,\n",
    "    \"dataset\": \"transformed_datasets/prompts_training/parsed_data_cues.jsonl\",\n",
    "    \"dataset_format\": \"input-output\",\n",
    "    \"source_max_len\": 256,\n",
    "    \"target_max_len\": 64,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_steps\": 4000,\n",
    "    \"learning_rate\": 0.0002,\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"seed\": 0,\n",
    "}\n",
    "roles_training_config = {\n",
    "    \"model_name_or_path\": \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"output_dir\": \"./output/spkatt-7b-roles\",\n",
    "    \"data_seed\": 42,\n",
    "    \"save_steps\": 200,\n",
    "    \"evaluation_strategy\": \"no\",\n",
    "    \"dataloader_num_workers\": 4,\n",
    "    \"lora_modules\": \"all\",\n",
    "    \"bf16\": True,\n",
    "    \"dataset\": \"transformed_datasets/prompts_training/parsed_data_roles.jsonl\",\n",
    "    \"dataset_format\": \"input-output\",\n",
    "    \"source_max_len\": 640,\n",
    "    \"target_max_len\": 256,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_steps\": 4000,\n",
    "    \"learning_rate\": 0.0002,\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"seed\": 0,\n",
    "}\n",
    "\n",
    "# 70B models\n",
    "# cues_training_config = {\"model_name_or_path\": \"meta-llama/Llama-2-70b-hf\",\n",
    "#                         \"output_dir\": \"./output/spkatt-70b-cues\",\n",
    "#                         \"data_seed\": 42,\n",
    "#                         \"save_steps\": 500,\n",
    "#                         \"evaluation_strategy\": \"no\",\n",
    "#                         \"dataloader_num_workers\": 4,\n",
    "#                         \"lora_modules\": \"all\",\n",
    "#                         \"bf16\": True,\n",
    "#                         \"dataset\": \"transformed_datasets/prompts_training/parsed_data_cues.jsonl\",\n",
    "#                         \"dataset_format\": \"input-output\",\n",
    "#                         \"source_max_len\": 256,\n",
    "#                         \"target_max_len\": 64,\n",
    "#                         \"per_device_train_batch_size\": 16,\n",
    "#                         \"gradient_accumulation_steps\": 1,\n",
    "#                         \"max_steps\": 2500,\n",
    "#                         \"learning_rate\": 0.0001,\n",
    "#                         \"lora_dropout\": 0.05,\n",
    "#                         \"seed\": 0,\n",
    "#                         }\n",
    "# roles_training_config = {\"model_name_or_path\": \"meta-llama/Llama-2-70b-hf\",\n",
    "#                          \"output_dir\": \"./output/spkatt-70b-roles\",\n",
    "#                          \"data_seed\": 42,\n",
    "#                          \"save_steps\": 500,\n",
    "#                          \"evaluation_strategy\": \"no\",\n",
    "#                          \"dataloader_num_workers\": 4,\n",
    "#                          \"lora_modules\": \"all\",\n",
    "#                          \"bf16\": True,\n",
    "#                          \"dataset\": \"transformed_datasets/prompts_training/parsed_data_roles.jsonl\",\n",
    "#                          \"dataset_format\": \"input-output\",\n",
    "#                          \"source_max_len\": 640,\n",
    "#                          \"target_max_len\": 256,\n",
    "#                          \"per_device_train_batch_size\": 8,\n",
    "#                          \"gradient_accumulation_steps\": 2,\n",
    "#                          \"max_steps\": 2500,\n",
    "#                          \"learning_rate\": 0.0001,\n",
    "#                          \"lora_dropout\": 0.05,\n",
    "#                          \"seed\": 0,\n",
    "#                          }\n",
    "\n",
    "train(cues_training_config)\n",
    "# train(roles_training_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"/home/ngr/models/llama-2-hf/70b\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=device_map,\n",
    "#     cache_dir=\"/home/ngr/.cache/huggingface/hub\",\n",
    "# )\n",
    "# checkpoint_dir = \"/home/ngr/repos/qlora3/experiments/exp008/exp008e/output/spkatt-70b-cues/checkpoint-2000/\"\n",
    "# model = PeftModel.from_pretrained(model, os.path.join(checkpoint_dir, \"adapter_model\"))\n",
    "# model = model.merge_and_unload()\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(model_name, legacy=False)\n",
    "# tokenizer.bos_token_id = 1\n",
    "\n",
    "# from transformers import pipeline\n",
    "\n",
    "# pipe = pipeline(\n",
    "#     task=\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=300\n",
    "# )\n",
    "# from langchain import HuggingFacePipeline\n",
    "\n",
    "# llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
