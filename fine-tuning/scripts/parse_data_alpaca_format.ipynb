{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc06f35-4a02-4ebd-b92c-2096552ae75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_path = './lmsys.json'  # TODO\n",
    "with open(data_path) as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435d23cd-ceec-4bda-8213-0acecb30c6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_file_cues = './parsed_data_cues.jsonl'\n",
    "new_file_roles = './parsed_data_roles.jsonl'\n",
    "\n",
    "# token to signal the end of the assistant's response\n",
    "separator = '</s>'\n",
    "\n",
    "all_prompts_cues = []\n",
    "all_prompts_roles = []\n",
    "for conv in data:\n",
    "    complete_prompt = ''\n",
    "    for i, turn in enumerate(conv['conversations']):\n",
    "        complete_prompt = complete_prompt.replace('all cuee',\n",
    "                                                  'all cues')  # FIXME fix this in script that creates lmsys.json\n",
    "        if turn['from'] == 'human':\n",
    "            complete_prompt += 'User: '\n",
    "            complete_prompt += turn['value']\n",
    "        elif turn['from'] == 'gpt':\n",
    "            complete_prompt += 'Assistant: '\n",
    "            sample = json.dumps({'input': complete_prompt, 'output': turn['value'] + separator})\n",
    "            if i == 1 and sample not in all_prompts_cues:  # TODO simplify or document this\n",
    "                all_prompts_cues.append(sample)\n",
    "            elif i == 3 and sample not in all_prompts_cues:\n",
    "                all_prompts_roles.append(sample)\n",
    "            elif i != 1 and i != 3:\n",
    "                print('something wrong here')\n",
    "            complete_prompt += turn['value'] + separator\n",
    "        complete_prompt += '\\n'\n",
    "\n",
    "# write parsed prompts to file\n",
    "with open(new_file_cues, 'w') as f:\n",
    "    f.write('\\n'.join(all_prompts_cues))\n",
    "\n",
    "with open(new_file_roles, 'w') as f:\n",
    "    f.write('\\n'.join(all_prompts_roles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f2b337-dc8e-4a69-9a00-6052f16ecb90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9399\n",
      "in: User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Frau Präsidentin !\n",
      "Assistant: \n",
      "out: Cues: #UNK#</s>\n",
      "\n",
      "in: User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Liebe Kolleginnen und Kollegen !\n",
      "Assistant: \n",
      "out: Cues: #UNK#</s>\n",
      "\n",
      "in: User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Bundeskanzlerin Angela Merkel hat auf der Klimakonferenz in Bonn gesprochen .\n",
      "Assistant: \n",
      "out: Cues: [gesprochen]</s>\n",
      "\n",
      "in: User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Sie hat dort den Klimawandel als eine zentrale Herausforderung für die Menschheit bezeichnet .\n",
      "Assistant: \n",
      "out: Cues: [bezeichnet]</s>\n",
      "\n",
      "in: User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Sie hat von einer Schicksalsfrage gesprochen .\n",
      "Assistant: \n",
      "out: Cues: [gesprochen]</s>\n"
     ]
    }
   ],
   "source": [
    "# check that the file with the cue prompts was written correctly\n",
    "with open(new_file_cues) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(f'Number of samples: {len(lines)}\\n')\n",
    "\n",
    "print('First 5 samples:')\n",
    "for l in lines[:5]:\n",
    "    print('in:', json.loads(l)['input'])\n",
    "    print('out:', json.loads(l)['output'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc762204-3c3f-48ee-839d-573cf286fba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5914\n",
      "in: User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Bundeskanzlerin Angela Merkel hat auf der Klimakonferenz in Bonn gesprochen .\n",
      "Assistant: Cues: [gesprochen]</s>\n",
      "User: Now I give you again the sentence only in addition with the two following sentences, because the roles can be partially contained in the following sentences.\n",
      "Text: Bundeskanzlerin Angela Merkel hat auf der Klimakonferenz in Bonn gesprochen . Sie hat dort den Klimawandel als eine zentrale Herausforderung für die Menschheit bezeichnet . Sie hat von einer Schicksalsfrage gesprochen .\n",
      "\n",
      "Now find all roles in the sentence associated with the cue 'gesprochen' you found in the beginning sentence.\n",
      "Assistant: \n",
      "out: cue: gesprochen\n",
      "ptc: #UNK#\n",
      "evidence: #UNK#\n",
      "medium: #UNK#\n",
      "topic: #UNK#\n",
      "addr: #UNK#\n",
      "message: #UNK#\n",
      "source: Bundeskanzlerin, Angela, Merkel</s>\n",
      "\n",
      "in: User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Sie hat dort den Klimawandel als eine zentrale Herausforderung für die Menschheit bezeichnet .\n",
      "Assistant: Cues: [bezeichnet]</s>\n",
      "User: Now I give you again the sentence only in addition with the two following sentences, because the roles can be partially contained in the following sentences.\n",
      "Text: Sie hat dort den Klimawandel als eine zentrale Herausforderung für die Menschheit bezeichnet . Sie hat von einer Schicksalsfrage gesprochen . Was sie damit meint , das sieht man , wenn man sich zum Beispiel die Situation der Inselstaaten anschaut .\n",
      "\n",
      "Now find all roles in the sentence associated with the cue 'bezeichnet' you found in the beginning sentence.\n",
      "Assistant: \n",
      "out: cue: bezeichnet\n",
      "ptc: #UNK#\n",
      "evidence: #UNK#\n",
      "medium: #UNK#\n",
      "topic: den, Klimawandel\n",
      "addr: #UNK#\n",
      "message: als, eine, zentrale, Herausforderung, für, die, Menschheit\n",
      "source: Sie</s>\n",
      "\n",
      "in: User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Sie hat von einer Schicksalsfrage gesprochen .\n",
      "Assistant: Cues: [gesprochen]</s>\n",
      "User: Now I give you again the sentence only in addition with the two following sentences, because the roles can be partially contained in the following sentences.\n",
      "Text: Sie hat von einer Schicksalsfrage gesprochen . Was sie damit meint , das sieht man , wenn man sich zum Beispiel die Situation der Inselstaaten anschaut . Die Fidschi-Inseln standen in besonderer Weise im Mittelpunkt der Konferenz , weil die Fidschis die Präsidentschaft übernommen hatten .\n",
      "\n",
      "Now find all roles in the sentence associated with the cue 'gesprochen' you found in the beginning sentence.\n",
      "Assistant: \n",
      "out: cue: gesprochen\n",
      "ptc: #UNK#\n",
      "evidence: #UNK#\n",
      "medium: #UNK#\n",
      "topic: #UNK#\n",
      "addr: #UNK#\n",
      "message: von, einer, Schicksalsfrage\n",
      "source: Sie</s>\n",
      "\n",
      "in: User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Was sie damit meint , das sieht man , wenn man sich zum Beispiel die Situation der Inselstaaten anschaut .\n",
      "Assistant: Cues: [meint], [sieht]</s>\n",
      "User: Now I give you again the sentence only in addition with the two following sentences, because the roles can be partially contained in the following sentences.\n",
      "Text: Was sie damit meint , das sieht man , wenn man sich zum Beispiel die Situation der Inselstaaten anschaut . Die Fidschi-Inseln standen in besonderer Weise im Mittelpunkt der Konferenz , weil die Fidschis die Präsidentschaft übernommen hatten . Wenn man bedenkt , dass es Inseln gibt , die von Überflutung bedroht sind , dass es dort Menschen gibt , die schon heute ihre Heimat verloren haben , deren Existenz , deren Inseln , deren Heimat durch den Klimawandel bedroht sind , wenn man sich vergegenwärtigt , dass es Umsiedlungen gibt , wenn man also weiß , dass es Menschen gibt , die wegen des Klimawandels flüchten - es gibt Menschen , die zu Klimaflüchtlingen werden - , dann muss man sagen : Wer etwas für die Bekämpfung der Fluchtursachen tun möchte , der muss stark für Klimaschutz sein .\n",
      "\n",
      "Now find all roles in the sentence associated with the cue 'meint' you found in the beginning sentence.\n",
      "Assistant: \n",
      "out: cue: meint\n",
      "ptc: #UNK#\n",
      "evidence: #UNK#\n",
      "medium: #UNK#\n",
      "topic: #UNK#\n",
      "addr: #UNK#\n",
      "message: Was\n",
      "source: sie</s>\n",
      "\n",
      "in: User: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being reproduced.\n",
      "I want you to extract all cues in the text below.\n",
      "If you find multiple words for one cue, you output them separated by commas.\n",
      "If no cue can be found in the given text, you output the string #UNK# as cue.\n",
      "Now extract all cues from the following sentence.\n",
      "Use the prefix \"Cues: \".\n",
      "Sentence: Was sie damit meint , das sieht man , wenn man sich zum Beispiel die Situation der Inselstaaten anschaut .\n",
      "Assistant: Cues: [meint], [sieht]</s>\n",
      "User: Now I give you again the sentence only in addition with the two following sentences, because the roles can be partially contained in the following sentences.\n",
      "Text: Was sie damit meint , das sieht man , wenn man sich zum Beispiel die Situation der Inselstaaten anschaut . Die Fidschi-Inseln standen in besonderer Weise im Mittelpunkt der Konferenz , weil die Fidschis die Präsidentschaft übernommen hatten . Wenn man bedenkt , dass es Inseln gibt , die von Überflutung bedroht sind , dass es dort Menschen gibt , die schon heute ihre Heimat verloren haben , deren Existenz , deren Inseln , deren Heimat durch den Klimawandel bedroht sind , wenn man sich vergegenwärtigt , dass es Umsiedlungen gibt , wenn man also weiß , dass es Menschen gibt , die wegen des Klimawandels flüchten - es gibt Menschen , die zu Klimaflüchtlingen werden - , dann muss man sagen : Wer etwas für die Bekämpfung der Fluchtursachen tun möchte , der muss stark für Klimaschutz sein .\n",
      "\n",
      "Now find all roles in the sentence associated with the cue 'sieht' you found in the beginning sentence.\n",
      "Assistant: \n",
      "out: cue: sieht\n",
      "ptc: #UNK#\n",
      "evidence: #UNK#\n",
      "medium: #UNK#\n",
      "topic: #UNK#\n",
      "addr: #UNK#\n",
      "message: das\n",
      "source: man</s>\n"
     ]
    }
   ],
   "source": [
    "# check that the file with the role prompts was written correctly\n",
    "with open(new_file_roles) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(f'Number of samples: {len(lines)}\\n')\n",
    "\n",
    "print('First 5 samples:')\n",
    "for l in lines[:5]:\n",
    "    print('in:', json.loads(l)['input'])\n",
    "    print('out:', json.loads(l)['output'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59fc1b42-8ec9-44b0-ba24-bb5bd9083a82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# encode all prompt inputs with the Llama 1 tokenizer (same as the Llama 2 tokenizer)\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'huggyllama/llama-7b',\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,  # Fast tokenizer giving issues.\n",
    "    tokenizer_type='llama'\n",
    ")\n",
    "\n",
    "lines_cues = []\n",
    "lines_roles = []\n",
    "with open(new_file_cues) as f:\n",
    "    lines_cues.extend(f.readlines())\n",
    "with open(new_file_roles) as f:\n",
    "    lines_roles.extend(f.readlines())\n",
    "\n",
    "encodings_cues = []\n",
    "encodings_roles = []\n",
    "for l in lines_cues:\n",
    "    enc = tokenizer.encode(json.loads(l)['input'])\n",
    "    encodings_cues.append(enc)\n",
    "for l in lines_roles:\n",
    "    enc = tokenizer.encode(json.loads(l)['input'])\n",
    "    encodings_roles.append(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d94e87-2e88-45ed-922e-ff8548b31c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cues\n",
      "323\n",
      "144.7142249175444\n",
      "7\n",
      "roles\n",
      "648\n",
      "326.9815691579303\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# check the length of the encoded prompts, needed to set the max length of the model in the fine-tuning scripts\n",
    "max_length_cues_in = 256\n",
    "max_length_roles_in = 640\n",
    "\n",
    "print('cues')\n",
    "len_enc = [len(e) for e in encodings_cues]\n",
    "print(f'max length: {max(len_enc)}')\n",
    "print(f'mean length: {np.mean(len_enc)}')\n",
    "print(f'number of samples longer than {max_length_cues_in}: {sum(np.array(len_enc) > max_length_cues_in)}')\n",
    "\n",
    "print('roles')\n",
    "len_enc = [len(e) for e in encodings_roles]\n",
    "print(f'max length: {max(len_enc)}')\n",
    "print(f'mean length: {np.mean(len_enc)}')\n",
    "print(f'number of samples longer than {max_length_roles_in}: {sum(np.array(len_enc) > max_length_roles_in)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f43d0115-22f3-47b6-9207-6494cceb5fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encode all prompt outputs with the Llama 1 tokenizer\n",
    "encodings_cues_out = []\n",
    "encodings_roles_out = []\n",
    "for l in lines_cues:\n",
    "    enc = tokenizer.encode(json.loads(l)['output'])\n",
    "    encodings_cues_out.append(enc)\n",
    "for l in lines_roles:\n",
    "    enc = tokenizer.encode(json.loads(l)['output'])\n",
    "    encodings_roles_out.append(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddd591f0-a25f-4f4c-837e-e76f2b483d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cues\n",
      "50\n",
      "10.385998510479839\n",
      "0\n",
      "roles\n",
      "259\n",
      "71.00067636117687\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# check the length of the encoded prompt outputs, needed to set the max length of the model in the fine-tuning scripts\n",
    "max_length_cues_out = 64\n",
    "max_length_roles_out = 256\n",
    "\n",
    "print('cues')\n",
    "len_enc = [len(e) for e in encodings_cues_out]\n",
    "print(f'max length: {max(len_enc)}')\n",
    "print(f'mean length: {np.mean(len_enc)}')\n",
    "print(f'number of samples longer than {max_length_cues_out}: {sum(np.array(len_enc) > max_length_cues_out)}')\n",
    "\n",
    "print('roles')\n",
    "len_enc = [len(e) for e in encodings_roles_out]\n",
    "print(f'max length: {max(len_enc)}')\n",
    "print(f'mean length: {np.mean(len_enc)}')\n",
    "print(f'number of samples longer than {max_length_roles_out}: {sum(np.array(len_enc) > max_length_roles_out)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlora",
   "language": "python",
   "name": "qlora"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
